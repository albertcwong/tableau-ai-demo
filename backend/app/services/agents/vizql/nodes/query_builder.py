"""Query builder node for constructing VizQL queries."""
import json
import logging
from typing import Dict, Any
from langchain_core.messages import HumanMessage, SystemMessage

from app.services.agents.vizql.state import VizQLAgentState
from app.services.agents.vizql.context_builder import build_full_compressed_context
from app.prompts.registry import prompt_registry
from app.services.ai.client import UnifiedAIClient
from app.core.config import settings
from app.services.metrics import track_node_execution

logger = logging.getLogger(__name__)


def _detect_and_apply_date_functions(query_draft: Dict[str, Any], user_query: str, enriched_schema: Any = None) -> Dict[str, Any]:
    """
    Automatically detect temporal grouping keywords and apply date functions to date fields.
    
    This is a programmatic fallback for when the LLM doesn't follow prompt instructions.
    
    Args:
        query_draft: The query generated by the LLM
        user_query: The user's original query text
        enriched_schema: Schema information to identify date fields
        
    Returns:
        Modified query with date functions applied where needed
    """
    user_query_lower = user_query.lower()
    
    # Detect temporal grouping keywords and map to functions
    temporal_patterns = {
        "trunc_month": ["by month", "monthly", "per month", "each month", "every month"],
        "trunc_year": ["by year", "yearly", "per year", "each year", "every year", "annually"],
        "trunc_quarter": ["by quarter", "quarterly", "per quarter", "each quarter", "every quarter"],
        "trunc_week": ["by week", "weekly", "per week", "each week", "every week"],
        "trunc_day": ["by day", "daily", "per day", "each day", "every day"]
    }
    
    # Check if any temporal keyword is present
    detected_function = None
    for func_name, keywords in temporal_patterns.items():
        if any(keyword in user_query_lower for keyword in keywords):
            detected_function = func_name.upper()
            logger.info(f"Detected temporal grouping keyword, will apply {detected_function} function")
            break
    
    # If no temporal keyword detected, return query as-is
    if not detected_function:
        return query_draft
    
    # Get date field names from schema
    date_field_names = set()
    if enriched_schema and isinstance(enriched_schema, dict):
        for field in enriched_schema.get("fields", []):
            data_type = field.get("dataType", "").upper()
            if data_type in ["DATE", "DATETIME", "TIMESTAMP"]:
                date_field_names.add(field.get("fieldCaption"))
    
    # If we don't have schema info, use common date field patterns
    if not date_field_names:
        # Common date field patterns
        date_patterns = ["date", "time", "datetime", "timestamp", "created", "modified", "order date", "ship date", "purchase date"]
        date_field_names = set([p.title() for p in date_patterns] + [p.upper() for p in date_patterns] + ["Order Date", "Ship Date"])
    
    # Check and fix fields in the query
    fields = query_draft.get("query", {}).get("fields", [])
    modified = False
    
    for field in fields:
        field_caption = field.get("fieldCaption", "")
        field_function = field.get("function")
        
        # Check if this is a date field without a function
        is_date_field = any(date_name.lower() in field_caption.lower() for date_name in date_field_names) or field_caption in date_field_names
        
        if is_date_field and not field_function and "calculation" not in field:
            # Apply the detected temporal function
            field["function"] = detected_function
            logger.warning(
                f"ðŸ”§ AUTO-FIX: Added '{detected_function}' function to date field '{field_caption}' "
                f"(detected from user query: '{user_query}')"
            )
            modified = True
    
    if modified:
        logger.info(f"Applied automatic date function fixes to query")
    
    return query_draft


def _detect_and_apply_count_functions(query_draft: Dict[str, Any], user_query: str, enriched_schema: Optional[Any] = None) -> Dict[str, Any]:
    """
    Automatically detect "how many" queries and apply COUNTD function.
    
    This is a programmatic fallback for when the LLM doesn't follow prompt instructions
    about counting distinct entities.
    
    Args:
        query_draft: The query generated by the LLM
        user_query: The user's original query text
        enriched_schema: Schema information to identify fields
        
    Returns:
        Modified query with COUNTD functions applied where needed
    """
    user_query_lower = user_query.lower()
    
    # Patterns that indicate count/distinct queries
    count_patterns = ["how many", "count of", "number of", "count distinct", "unique count"]
    
    # Check if any count pattern is present
    needs_count = any(pattern in user_query_lower for pattern in count_patterns)
    
    if not needs_count:
        return query_draft
    
    # Get fields from query
    fields = query_draft.get("query", {}).get("fields", [])
    
    # Check if query has exactly 1 field without a function
    # This is the pattern: "how many customers" â†’ field without function
    if len(fields) == 1:
        field = fields[0]
        field_caption = field.get("fieldCaption", "")
        has_function = "function" in field
        
        if not has_function and field_caption:
            # Apply COUNTD function
            field["function"] = "COUNTD"
            logger.warning(
                f"ðŸ”§ AUTO-FIX: Added 'COUNTD' function to field '{field_caption}' "
                f"(detected 'how many' pattern in user query: '{user_query}')"
            )
            return query_draft
    
    # Check for fields that match the entity being counted
    # E.g., "how many customers" with field "Customer Name" without function
    for field in fields:
        field_caption = field.get("fieldCaption", "")
        has_function = "function" in field
        
        if not has_function and field_caption:
            # Check if field name is mentioned in the query
            field_words = field_caption.lower().split()
            
            # Check if user query contains the field entity
            # E.g., "how many customers" and field is "Customer Name"
            for word in field_words:
                # Common entity names
                if word in ["customer", "order", "product", "region", "category", "state", "city", "country"]:
                    # Check if this word appears after "how many" or "count of"
                    for pattern in count_patterns:
                        pattern_idx = user_query_lower.find(pattern)
                        if pattern_idx >= 0:
                            # Check if the word appears near the pattern
                            query_after_pattern = user_query_lower[pattern_idx:]
                            if word in query_after_pattern:
                                field["function"] = "COUNTD"
                                logger.warning(
                                    f"ðŸ”§ AUTO-FIX: Added 'COUNTD' function to field '{field_caption}' "
                                    f"(detected '{pattern} {word}' in user query)"
                                )
                                return query_draft
    
    return query_draft


def _detect_and_apply_context_filters(query_draft: Dict[str, Any], user_query: str) -> Dict[str, Any]:
    """
    Automatically detect hierarchical filter dependencies and apply context:true appropriately.
    
    This is a programmatic fallback for when the LLM doesn't follow prompt instructions
    about context filters.
    
    Context filters are needed when one filter establishes a scope for another filter.
    Example: "given the top region, show me the top 3 customers"
    - First filter (top region) needs context:true
    - Second filter (top 3 customers) operates within that context
    
    Args:
        query_draft: The query generated by the LLM
        user_query: The user's original query text
        
    Returns:
        Modified query with context:true applied where needed
    """
    user_query_lower = user_query.lower()
    
    # Linguistic patterns that indicate hierarchical dependencies
    hierarchical_patterns = [
        # Pattern: "given X, show/find Y"
        (r"given\s+(?:the\s+)?(?:top|best|largest|highest|biggest)\s+(\d+\s+)?(\w+)(?:.*?)(?:,|\band\b|\bthen\b)?\s*(?:show|find|give|get|what|which)", 
         "given X, show Y"),
        
        # Pattern: "for the X, find/show Y"
        (r"for\s+(?:the\s+)?(?:top|best|largest|highest|biggest)\s+(\d+\s+)?(\w+)(?:.*?)(?:,|\band\b|\bthen\b)?\s*(?:show|find|give|get|what|which)",
         "for X, find Y"),
        
        # Pattern: "within X, show Y"
        (r"within\s+(?:the\s+)?(?:top|best|largest|highest|biggest)?\s*(\d+\s+)?(\w+)(?:.*?)(?:,|\band\b|\bthen\b)?\s*(?:show|find|give|get|what|which)",
         "within X, show Y"),
        
        # Pattern: "in X, what/which are Y"
        (r"in\s+(?:the\s+)?(?:top|best|largest|highest|biggest)?\s*(\d+\s+)?(\w+)(?:.*?)(?:,|\band\b|\bthen\b)?\s*(?:show|find|give|get|what|which)",
         "in X, what are Y"),
        
        # Pattern: "first X, then Y"
        (r"first\s+(?:find|get|show|the)?\s*(?:top|best|largest|highest|biggest)?\s*(\d+\s+)?(\w+)(?:.*?)(?:,|\band\b)?\s*(?:then|after|next)",
         "first X, then Y"),
    ]
    
    # Check if any hierarchical pattern is present
    import re
    hierarchical_detected = False
    for pattern, pattern_name in hierarchical_patterns:
        if re.search(pattern, user_query_lower):
            hierarchical_detected = True
            logger.info(f"Detected hierarchical filter pattern: '{pattern_name}' in user query")
            break
    
    # If no hierarchical pattern detected, return query as-is
    if not hierarchical_detected:
        return query_draft
    
    # Get filters from query
    filters = query_draft.get("query", {}).get("filters", [])
    
    # If we don't have multiple filters, no context needed
    if len(filters) < 2:
        return query_draft
    
    # Apply context logic:
    # 1. If we have 2 filters and hierarchical pattern detected:
    #    - First filter gets context:true
    #    - Second filter operates within that context
    # 
    # 2. Priority for context filters (which should be applied first):
    #    a) SET filters (specific value filters)
    #    b) DATE filters (time ranges)
    #    c) TOP filters with lower howMany (broader scope)
    #    d) QUANTITATIVE filters
    
    modified = False
    
    # Check if any filter already has context:true
    has_context = any(f.get("context") for f in filters)
    
    if not has_context and len(filters) == 2:
        # Simple case: 2 filters, no context set yet
        first_filter = filters[0]
        
        # Apply context to first filter if it's a valid type
        filter_type = first_filter.get("filterType", "")
        if filter_type in ["SET", "TOP", "QUANTITATIVE_NUMERICAL", "DATE"]:
            first_filter["context"] = True
            logger.warning(
                f"ðŸ”§ AUTO-FIX: Applied context:true to first filter (type: {filter_type}) "
                f"due to hierarchical pattern detected in: '{user_query}'"
            )
            modified = True
    
    elif not has_context and len(filters) > 2:
        # Complex case: 3+ filters
        # Heuristic: Apply context to broader scope filters (SET, DATE, or TOP with smaller howMany)
        
        # Find SET or DATE filters first (they typically define broad scopes)
        for i, f in enumerate(filters):
            filter_type = f.get("filterType", "")
            if filter_type in ["SET", "DATE"] and not f.get("context"):
                f["context"] = True
                logger.warning(
                    f"ðŸ”§ AUTO-FIX: Applied context:true to {filter_type} filter at position {i} "
                    f"due to hierarchical pattern detected in: '{user_query}'"
                )
                modified = True
                break
        
        # If no SET/DATE found, look for TOP filters and apply context to the one with smaller howMany
        if not modified:
            top_filters = [(i, f) for i, f in enumerate(filters) if f.get("filterType") == "TOP"]
            if len(top_filters) >= 2:
                # Sort by howMany (ascending), smaller N = broader scope
                top_filters_sorted = sorted(top_filters, key=lambda x: x[1].get("howMany", 999))
                # Apply context to the first (smallest N)
                idx, first_top = top_filters_sorted[0]
                first_top["context"] = True
                logger.warning(
                    f"ðŸ”§ AUTO-FIX: Applied context:true to TOP filter with howMany={first_top.get('howMany')} "
                    f"due to hierarchical pattern detected in: '{user_query}'"
                )
                modified = True
    
    if modified:
        logger.info(f"Applied automatic context filter fixes to query")
    
    return query_draft


@track_node_execution("vizql", "query_builder")
async def build_query_node(state: VizQLAgentState) -> Dict[str, Any]:
    """
    Construct VizQL Data Service query from intent and schema.
    
    This is an "Act" step in ReAct.
    """
    try:
        schema = state.get("schema")
        if not schema:
            return {
                **state,
                "error": "Schema not available. Cannot build query.",
                "query_draft": None
            }
        
        datasource_ids = state.get("context_datasources", [])
        if not datasource_ids:
            return {
                **state,
                "error": "No datasource ID available.",
                "query_draft": None
            }
        
        datasource_id = datasource_ids[0]
        
        # Check if we have enriched schema (from Phase 2)
        enriched_schema = state.get("enriched_schema")
        
        # Build compressed context if enriched schema is available
        if enriched_schema:
            logger.info("Using enriched schema with compressed context")
            compressed_context = build_full_compressed_context(
                enriched_schema=enriched_schema,
                user_query=state.get("user_query", ""),
                required_measures=state.get("required_measures", []),
                required_dimensions=state.get("required_dimensions", []),
                required_filters=state.get("required_filters", {}),
                topN=state.get("topN", {"enabled": False}),
                sorting=state.get("sorting", []),
                calculations=state.get("calculations", []),
                bins=state.get("bins", [])
            )
            
            # Split compressed context into components for prompt template
            context_lines = compressed_context.split("\n")
            compressed_schema_lines = []
            semantic_hints_lines = []
            field_lookup_lines = []
            parsed_intent_lines = []
            current_section = None
            
            for line in context_lines:
                if line.startswith("## Available Fields"):
                    current_section = "schema"
                    compressed_schema_lines.append(line)
                elif line.startswith("## Query Construction Hints"):
                    current_section = "hints"
                    semantic_hints_lines.append(line)
                elif line.startswith("## Field Matching Hints"):
                    current_section = "lookup"
                    field_lookup_lines.append(line)
                elif line.startswith("## Parsed Intent"):
                    current_section = "intent"
                    parsed_intent_lines.append(line)
                elif current_section == "schema":
                    compressed_schema_lines.append(line)
                elif current_section == "hints":
                    semantic_hints_lines.append(line)
                elif current_section == "lookup":
                    field_lookup_lines.append(line)
                elif current_section == "intent":
                    parsed_intent_lines.append(line)
            
            compressed_schema = "\n".join(compressed_schema_lines) if compressed_schema_lines else ""
            semantic_hints = "\n".join(semantic_hints_lines) if semantic_hints_lines else ""
            field_lookup_hints = "\n".join(field_lookup_lines) if field_lookup_lines else ""
            parsed_intent = "\n".join(parsed_intent_lines) if parsed_intent_lines else ""
            
            # Get query construction prompt with compressed context
            system_prompt = prompt_registry.get_prompt(
                "agents/vizql/query_construction.txt",
                variables={
                    "compressed_schema": compressed_schema,
                    "semantic_hints": semantic_hints,
                    "field_lookup_hints": field_lookup_hints,
                    "parsed_intent": parsed_intent,
                    "datasource_id": datasource_id
                }
            )
        else:
            # Fallback to basic schema format (backward compatibility)
            logger.info("Using basic schema (enrichment unavailable)")
            # Build parsed intent section even without enriched schema
            parsed_intent_parts = []
            if state.get("topN", {}).get("enabled"):
                topN = state.get("topN", {})
                parsed_intent_parts.append("## Parsed Intent")
                parsed_intent_parts.append("**CRITICAL: TOP N PATTERN DETECTED**")
                parsed_intent_parts.append(f"User wants top/bottom {topN.get('howMany', 'N')} {topN.get('dimensionField', 'dimension')} by {topN.get('measureField', 'measure')}")
                parsed_intent_parts.append(f"Direction: {topN.get('direction', 'TOP')}")
                parsed_intent_parts.append("**YOU MUST USE TOP FILTER, NOT SORTING!**")
            parsed_intent = "\n".join(parsed_intent_parts) if parsed_intent_parts else ""
            
            system_prompt = prompt_registry.get_prompt(
                "agents/vizql/query_construction.txt",
                variables={
                    "compressed_schema": f"## Available Fields\n{json.dumps(schema.get('columns', []), indent=2)}",
                    "semantic_hints": "## Query Construction Hints\nUsing basic schema. Field roles may not be available.",
                    "field_lookup_hints": "",
                    "parsed_intent": parsed_intent,
                    "datasource_id": datasource_id
                }
            )
        
        # Include few-shot examples
        examples = prompt_registry.get_examples("agents/vizql/examples.yaml")
        messages = prompt_registry.build_few_shot_prompt(
            system_prompt,
            examples,
            f"Build query for: {state['user_query']}"
        )
        
        # Initialize AI client with API key from state
        api_key = state.get("api_key")
        model = state.get("model", "gpt-4")
        
        # Validate API key is present
        if not api_key:
            logger.error("API key missing from state - cannot make gateway request")
            return {
                **state,
                "error": "Failed to build query: Authorization header required for direct authentication",
                "query_draft": None
            }
        
        ai_client = UnifiedAIClient(
            gateway_url=settings.GATEWAY_BASE_URL,
            api_key=api_key
        )
        
        # Call AI - pass api_key explicitly to ensure Authorization header is sent
        response = await ai_client.chat(
            model=model,
            messages=messages,
            api_key=api_key
        )
        
        # Parse query JSON
        try:
            content = response.content.strip()
            # Remove markdown code blocks if present
            if content.startswith("```"):
                lines = content.split("\n")
                # Find JSON block
                json_start = None
                json_end = None
                for i, line in enumerate(lines):
                    if "```json" in line.lower() or "```" in line:
                        if json_start is None:
                            json_start = i + 1
                        else:
                            json_end = i
                            break
                if json_start and json_end:
                    content = "\n".join(lines[json_start:json_end])
                elif json_start:
                    content = "\n".join(lines[json_start:-1])
            
            query_draft = json.loads(content)
            
            # Ensure query has required structure
            if "datasource" not in query_draft:
                query_draft["datasource"] = {"datasourceLuid": datasource_id}
            if "query" not in query_draft:
                query_draft["query"] = {}
            if "options" not in query_draft:
                query_draft["options"] = {
                    "returnFormat": "OBJECTS",
                    "disaggregate": False
                }
            
            # CRITICAL: Apply automatic date function detection and correction
            # This ensures date fields have proper temporal functions even if LLM missed them
            user_query = state.get("user_query", "")
            query_draft = _detect_and_apply_date_functions(query_draft, user_query, enriched_schema)
            
            # CRITICAL: Apply automatic COUNTD detection for "how many" queries
            # This ensures count queries have COUNTD function even if LLM missed it
            query_draft = _detect_and_apply_count_functions(query_draft, user_query, enriched_schema)
            
            # CRITICAL: Apply automatic context filter detection
            # This ensures hierarchical filter dependencies are properly handled
            query_draft = _detect_and_apply_context_filters(query_draft, user_query)
            
        except json.JSONDecodeError as e:
            logger.error(f"Failed to parse query JSON: {e}. Response: {response.content}")
            return {
                **state,
                "error": f"Failed to parse query JSON: {str(e)}",
                "query_draft": None
            }
        
        # Don't increment query_version here - it's incremented in refiner
        # Only increment on initial build (when query_version is 0 or missing)
        query_version = state.get("query_version", 0)
        if query_version == 0:
            query_version = 1
        
        return {
            **state,
            "query_draft": query_draft,
            "query_version": query_version,
            "current_thought": f"Built query version {query_version} with {len(query_draft.get('query', {}).get('fields', []))} fields"
        }
    except Exception as e:
        logger.error(f"Error building query: {e}", exc_info=True)
        return {
            **state,
            "error": f"Failed to build query: {str(e)}",
            "query_draft": None
        }
